# yolov2 by tf2


---

使用 **tensorflow2.0** 实现的 **yolo**_(you only look once)_ v2算法

---

## 算法效果

## 算法原理

---

#### 网络的输出

---

网络最终输出一个`(19,19,5,85)`的张量，其中`[i,j,a,:]` 
表示在第`[i,j]`单元格的第`a`个`anchor-box`的预测结果，由`4`部分组成

1. `[0:2]` 存储了对象中心在单元格内的位置`(x,y)`坐标
   - 经过`sigmoid`函数映射，范围限制在`0～1`
2. `[2:4]` 存储了对象的宽高`(w,h)`
   - 经过`exp`函数映射得到关于对应`anchor-box`的宽高系数，必须大于`0`
3. `[4:5]` 存储了该`anchor-box`包含对象的置信度(概率)
   - 经过`sigmoid`函数映射，范围限制在`0～1`
4. `[5:85]` 存储了该`anchor-box`包含的对象关于`80`个类别的概率分布
   - 经过`softmax`归一化，范围限制在`0～1`，总和为`1`

注意网络输出值并没有经过上面所描述的映射，

---

#### 人工标签

维度是`(K,5)`的张量，`K`为图片中包含的对象数量，每个对象由`3`部分决定

1. `[0:2]` 存储了对象中心在整张图片的相对位置`(x,y)`，范围在`0～1`
2. `[2:4]` 存储了对象的宽高`(w,h)`，范围在`0～1`
3. `[4:5]` 存储了对象的类别`class`，范围在`0～79`

#### 人工标签转换

人工标签的维度是`(K,5)`，显然与网络输出维度不符合，为了计算网络`loss`，我们将对
人工标签进行转换




